{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import argparse\n",
    "import munch\n",
    "import yaml\n",
    "from utils.vis_utils import plot_single_pcd\n",
    "from utils.train_utils import *\n",
    "from utils.ri_utils import *\n",
    "from utils.model_utils import *\n",
    "from dataset import ShapeNetH5\n",
    "config_path = 'cfgs/ri_vrcnet.yaml'\n",
    "args = munch.munchify(yaml.safe_load(open(config_path)))\n",
    "exp_name = os.path.basename(args.load_model)\n",
    "log_dir = os.path.dirname(args.load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10400, 2048, 3)\n",
      "(400, 2048, 3)\n",
      "(10400,)\n",
      "Length of dataset: 10400\n"
     ]
    }
   ],
   "source": [
    "dataset = ShapeNetH5(train=False, novel_input=True, npoints=args.num_points)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size,\n",
    "                                              shuffle=False, num_workers=int(args.workers))\n",
    "dataset_length = len(dataset)\n",
    "print('Length of dataset:', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 6.25 GiB (GPU 0; 10.76 GiB total capacity; 37.50 MiB already allocated; 3.36 GiB free; 6.27 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2c6185052648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_edge_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_knn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VRCNet/utils/model_utils.py\u001b[0m in \u001b[0;36mknn\u001b[0;34m(x, k)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0minner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mpairwise_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mxx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minner\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.25 GiB (GPU 0; 10.76 GiB total capacity; 37.50 MiB already allocated; 3.36 GiB free; 6.27 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2,5'\n",
    "data = torch.from_numpy(dataset.gt_data).cuda()\n",
    "data = data.transpose(1,2).contiguous()\n",
    "data_knn = get_edge_features(data, knn(data, 5))\n",
    "data_knn = data_knn - data.unsqueeze(2).repeat(1,1,10,1)\n",
    "data = data.transose(1,2).contiguous()\n",
    "data_knn = data_knn.transose(1,3).contiguous()\n",
    "a1, a2, a3, data_new = acenn_rir_feature(data_knn, data)\n",
    "data_new = inverse_point_projection_feature(a1, a2, a3, data_new)\n",
    "data_rec = data_new.cuda()\n",
    "cd_p, cd_t = calc_cd(data, data_rec)\n",
    "print(cd_p.mean())\n",
    "print(cd_t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_projection_feature(points, axis1=None, axis2=None, axis3=None, method='pca'):\n",
    "    # Input shape: [*, num_point, 3]\n",
    "    # Return: [*, num_point, 3]\n",
    "    num_point = points.size()[-2]\n",
    "    batch_size = points.size()[0]\n",
    "    points_reshape = points.view(-1, num_point, 3)\n",
    "    pseudo_batch_size = points_reshape.size()[0]\n",
    "            \n",
    "    if axis1 is not None:\n",
    "        axis1, axis2, axis3 = axis1, axis2, axis3\n",
    "    elif method == 'pca':\n",
    "        # Using PCA to define 3 axises\n",
    "        _, _, V = torch.pca_lowrank(points_reshape)\n",
    "        axis1, axis2, axis3 = V.chunk(3, dim=-1)\n",
    "        axis1 = axis1.squeeze()\n",
    "        axis2 = axis2.squeeze()\n",
    "        axis3 = axis3.squeeze()\n",
    "        axis1 = axis1 / (torch.norm(axis1, 2, -1, keepdim=True) + 1e-7)\n",
    "        axis2 = axis2 / (torch.norm(axis2, 2, -1, keepdim=True) + 1e-7)\n",
    "        axis3 = axis3 / (torch.norm(axis3, 2, -1, keepdim=True) + 1e-7)\n",
    "    elif method == 'srinet':\n",
    "        vector_norm = torch.sqrt(torch.sum(points_reshape * points_reshape, 2, keepdim=False))\n",
    "        # Calculate 3 axises\n",
    "    \n",
    "        # Axis 1 is the vector with the maximum norm\n",
    "        _, ids1 = torch.max(vector_norm, 1, keepdim=False)\n",
    "        batch_indices = range(pseudo_batch_size)\n",
    "        axis1 = torch.cat([points_reshape[batch_indice, id1, :].unsqueeze(0) for (batch_indice, id1) in zip(batch_indices, ids1)], 0)\n",
    "        axis1 = axis1 / (torch.norm(axis1, 2, 1, keepdim=True) + 1e-7)\n",
    "    \n",
    "        # Axis 2 is the vector with the minimum norm\n",
    "        _, ids2 = torch.min(vector_norm, 1, keepdim=False)\n",
    "        axis2 = torch.cat([points_reshape[batch_indice, id2, :].unsqueeze(0) for (batch_indice, id2) in zip(batch_indices, ids2)], 0)\n",
    "        axis2 = axis2 / (torch.norm(axis2, 2, 1, keepdim=True) + 1e-7)\n",
    "        \n",
    "        # Axis 3 is the cross result of axis 1 and axis 2\n",
    "        axis3 = torch.cross(axis1, axis2, dim=1)\n",
    "        axis3 = axis3 / (torch.norm(axis3, 2, 1, keepdim=True) + 1e-7)\n",
    "        \n",
    "    c1 = torch.sum(points_reshape * axis1.unsqueeze(1), 2, keepdim=True)\n",
    "    c2 = torch.sum(points_reshape * axis2.unsqueeze(1), 2, keepdim=True)\n",
    "    c3 = torch.sum(points_reshape * axis3.unsqueeze(1), 2, keepdim=True)\n",
    "        \n",
    "    new_c = torch.cat([c1, c2, c3], 2)\n",
    "    if points.dim() == 4:\n",
    "        new_c = new_c.view(batch_size, -1, num_point, 3)\n",
    "    \n",
    "    assert (new_c.size() == points.size())\n",
    "    return axis1, axis2, axis3, new_c\n",
    "\n",
    "\n",
    "def inverse_point_projection_feature(axis1, axis2, axis3, points):\n",
    "    # Axis shape: [batch_size, 3]\n",
    "    # Input shape: [batch_size, num_point, 3]\n",
    "    # Return: [batch_size, num_point, 3]\n",
    "    if len(list(points.size())) == 2 and len(list(axis1.size())) == 1:\n",
    "        axis1 = axis1[None,:]\n",
    "        axis2 = axis2[None,:]\n",
    "        axis3 = axis3[None,:]\n",
    "        points = points[None,:]\n",
    "\n",
    "    batch_size = points.size()[0]\n",
    "    num_point = points.size()[1]\n",
    "    \n",
    "    A = torch.cat([axis1.unsqueeze(2), axis2.unsqueeze(2), axis3.unsqueeze(2)], dim=2)\n",
    "    A = torch.transpose(A, 1, 2).unsqueeze(1).repeat(1, num_point, 1, 1)\n",
    "    X = torch.matmul(torch.linalg.pinv(A), points.unsqueeze(3)).squeeze()\n",
    "    \n",
    "    return X.squeeze()\n",
    "\n",
    "def acenn_rir_feature(points, center):\n",
    "    batch_size, num_point, k, _ = points.size()\n",
    "    \n",
    "    axis1 = center / (torch.norm(center, 2, 2, keepdim=True) + 1e-7)\n",
    "    \n",
    "    m = points.mean(dim=2, keepdim=False)\n",
    "    axis2 = m - axis1 * torch.sum(m * axis1, 2, keepdim=True)\n",
    "    axis2 = axis2 / (torch.norm(axis2, 2, 2, keepdim=True) + 1e-7)\n",
    "    \n",
    "    axis3 = torch.cross(axis1, axis2, dim=2)\n",
    "    axis3 = axis3 / (torch.norm(axis3, 2, 2, keepdim=True) + 1e-7)\n",
    "    \n",
    "    c1 = torch.sum(points * axis1.unsqueeze(2), 3, keepdim=True)\n",
    "    c2 = torch.sum(points * axis2.unsqueeze(2), 3, keepdim=True)\n",
    "    c3 = torch.sum(points * axis3.unsqueeze(2), 3, keepdim=True)\n",
    "        \n",
    "    new_c = torch.cat([c1, c2, c3], 3)\n",
    "    \n",
    "    assert (new_c.size() == points.size())\n",
    "    return axis1, axis2, axis3, new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1,2],[3,4]])\n",
    "B = torch.tensor([0,1])\n",
    "A[B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_clone = torch.clone(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_transform(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inverse_point_projection_feature(axis1, axis2, axis3, dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1600e-06, device='cuda:0')\n",
      "tensor(4.2582e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "data_old = input_clone.to(device)\n",
    "data_rec = X.to(device)\n",
    "cd_p, cd_t = calc_cd(data_old, data_rec)\n",
    "print(cd_p.mean())\n",
    "print(cd_t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = 'images/temp'\n",
    "idx_to_plot = [i for i in range(0, 1600, 75)]\n",
    "save_path = log_dir\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for idx in idx_to_plot:\n",
    "    pic = 'object_%d.png' % idx\n",
    "    #ply = 'object_%d.ply' % idx\n",
    "    plot_single_pcd(X[idx], os.path.join(log_dir, pic))\n",
    "    #pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(X[idx]))\n",
    "    #o3d.io.write_point_cloud(os.path.join(log_dir, ply), pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 2048, 5])\n",
      "torch.Size([400, 2048, 5])\n"
     ]
    }
   ],
   "source": [
    "data_new = torch.cat([dataset_new, torch.zeros(400, 2048, 1)], 2)\n",
    "print(data_new.size())\n",
    "data_rot = torch.cat([n_dataset_new, torch.zeros(400, 2048, 1)], 2)\n",
    "print(data_rot.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 100000\n",
    "dummy = np.vstack((np.zeros(z), np.zeros(z), np.ones(z))).T\n",
    "print(dummy.shape)\n",
    "for i in range(z):\n",
    "    azi = np.random.rand() * 2 * np.pi\n",
    "    R = np.array(((np.cos(azi), np.sin(azi), 0),\n",
    "                              (-np.sin(azi), np.cos(azi), 0),\n",
    "                              (0, 0, 1)))\n",
    "    x = np.random.rand(2)\n",
    "    v = np.array((np.cos(2*np.pi*x[0])*np.sqrt(x[1]),\n",
    "                              np.sin(2*np.pi*x[0])*np.sqrt(x[1]),\n",
    "                              np.sqrt(1-x[1])))\n",
    "    H = np.eye(3) - 2 * np.outer(v, v)\n",
    "    rotation_matrix = -H @ R\n",
    "    dummy[i] = dummy[i] @ rotation_matrix\n",
    "plot_single_pcd(dummy, os.path.join('images/temp', 'uniform.png'))\n",
    "pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(dummy))\n",
    "o3d.io.write_point_cloud('images/temp/uniform.ply', pcd)\n",
    "\n",
    "dummy = np.vstack((np.zeros(z), np.zeros(z), np.ones(z))).T\n",
    "for i in range(z):\n",
    "    angs = np.random.rand(3) * 2 * np.pi\n",
    "    rot_z = np.array(((np.cos(angs[0]), -np.sin(angs[0]), 0),\n",
    "                                  (np.sin(angs[0]), np.cos(angs[0]), 0),\n",
    "                                  (0, 0, 1)))\n",
    "    rot_y = np.array(((np.cos(angs[1]), 0, np.sin(angs[1])),\n",
    "                                  (0, 1, 0),\n",
    "                                  (-np.sin(angs[1]), 0, np.cos(angs[1]))))\n",
    "    rot_x = np.array(((1, 0, 0),\n",
    "                                  (0, np.cos(angs[2]), -np.sin(angs[2])),\n",
    "                                  (0, np.sin(angs[2]), np.cos(angs[2]))))\n",
    "    rotation_matrix = rot_z @ rot_y @ rot_x\n",
    "    dummy[i] = dummy[i] @ rotation_matrix\n",
    "plot_single_pcd(dummy, os.path.join('images/temp', 'euler.png'))\n",
    "pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(dummy))\n",
    "o3d.io.write_point_cloud('images/temp/euler.ply', pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded compiled 3D CUDA chamfer distance\n",
      "INFO:root:siamese_vrcnet's previous weights loaded.\n"
     ]
    }
   ],
   "source": [
    "model_module = importlib.import_module('.%s' % args.model_name, 'models')\n",
    "net = torch.nn.DataParallel(model_module.Model(args))\n",
    "net.cuda()\n",
    "net.module.load_state_dict(torch.load(args.load_model)['net_state_dict'])\n",
    "logging.info(\"%s's previous weights loaded.\" % args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "# azimuthal_angle = 90\n",
    "# angle coordinates are askewed\n",
    "#rotation_matrix = np.array(((0,0,1),(0,1,0),(-1,0,0)))\n",
    "#rotation_matrix = np.array(((0,-1,0),(1,0,0),(0,0,1)))\n",
    "dataset_plot = dataset_test.gt_data.copy()\n",
    "#dataset_plot = dataset_test.gt_data @ rotation_matrix\n",
    "print(dataset_plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2048, 3)\n",
      "(41600, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.random.seed(5)\n",
    "for i in range(dataset_test.gt_data.shape[0]):\n",
    "    angs = np.random.rand(3) * 2 * np.pi\n",
    "    rot_z = np.array(((np.cos(angs[0]), -np.sin(angs[0]), 0),\n",
    "                      (np.sin(angs[0]), np.cos(angs[0]), 0),\n",
    "                      (0, 0, 1)))\n",
    "    rot_y = np.array(((np.cos(angs[1]), 0, np.sin(angs[1])),\n",
    "                      (0, 1, 0),\n",
    "                      (-np.sin(angs[1]), 0, np.cos(angs[1]))))\n",
    "    rot_x = np.array(((1, 0, 0),\n",
    "                      (0, np.cos(angs[2]), -np.sin(angs[2])),\n",
    "                      (0, np.sin(angs[2]), np.cos(angs[2]))))\n",
    "    rotation_matrix = rot_z @ rot_y @ rot_x\n",
    "    #rotation_matrix = np.array(((0,0,1),(0,1,0),(-1,0,0)))\n",
    "    #dataset_test.gt_data[i] = dataset_test.gt_data[i] @ rotation_matrix\n",
    "    dataset_test.input_data[26*i:26*i+25] = dataset_test.input_data[26*i:26*i+25] @ rotation_matrix\n",
    "print(dataset_test.gt_data.shape)\n",
    "print(dataset_test.input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 2048, 3)\n",
      "(41600, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(dataset_test.gt_data.shape[0]):\n",
    "    ang = np.random.rand() * 2 * np.pi\n",
    "    rotation_matrix = np.array(((np.cos(ang), 0, np.sin(ang)),\n",
    "                      (0, 1, 0),\n",
    "                      (-np.sin(ang), 0, np.cos(ang))))\n",
    "    dataset_test.gt_data[i] = dataset_test.gt_data[i] @ rotation_matrix\n",
    "    dataset_test.input_data[26*i:26*i+25] = dataset_test.input_data[26*i:26*i+25] @ rotation_matrix\n",
    "print(dataset_test.gt_data.shape)\n",
    "print(dataset_test.input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Testing...\n"
     ]
    }
   ],
   "source": [
    "metrics = ['cd_p', 'cd_t', 'f1']\n",
    "test_loss_meters = {m: AverageValueMeter() for m in metrics}\n",
    "test_loss_cat = torch.zeros([16, 3], dtype=torch.float32).cuda()\n",
    "cat_num = torch.ones([16, 1], dtype=torch.float32).cuda() * 150\n",
    "cat_name = ['airplane', 'cabinet', 'car', 'chair', 'lamp', 'sofa', 'table', 'vessel',\n",
    "            'bed', 'bench', 'bookshelf', 'bus', 'guitar', 'motorbike', 'pistol', 'skateboard']\n",
    "idx_to_plot = [i for i in range(0, 41600, 75)]\n",
    "logging.info('Testing...')\n",
    "if args.save_vis:\n",
    "    save_gt_path = os.path.join(log_dir, 'pics', 'gt')\n",
    "    save_partial_path = os.path.join(log_dir, 'pics', 'partial')\n",
    "    save_completion_path = os.path.join(log_dir, 'pics', 'completion')\n",
    "    os.makedirs(save_gt_path, exist_ok=True)\n",
    "    os.makedirs(save_partial_path, exist_ok=True)\n",
    "    os.makedirs(save_completion_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:test [0/1300]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataloader_test):\n",
    "            \n",
    "        label, inputs_cpu, gt_cpu = data\n",
    "        # mean_feature = None\n",
    "\n",
    "        inputs = inputs_cpu.float().cuda()\n",
    "        gt = gt_cpu.float().cuda()\n",
    "        inputs = inputs.transpose(2, 1).contiguous()\n",
    "        # result_dict = net(inputs, gt, is_training=False, mean_feature=mean_feature)\n",
    "        result_dict = net(inputs, gt, is_training=False)\n",
    "        for k, v in test_loss_meters.items():\n",
    "            v.update(result_dict[k].mean().item())\n",
    "\n",
    "        for j, l in enumerate(label):\n",
    "            for ind, m in enumerate(metrics):\n",
    "                test_loss_cat[int(l), ind] = result_dict[m][int(j)]\n",
    "\n",
    "        if i % args.step_interval_to_print == 0:\n",
    "            logging.info('test [%d/%d]' % (i, dataset_length / args.batch_size))\n",
    "\n",
    "        if args.save_vis:\n",
    "            for j in range(args.batch_size):\n",
    "                idx = i * args.batch_size + j\n",
    "                if idx in idx_to_plot:\n",
    "                    pic = 'object_%d.png' % idx\n",
    "                    plot_single_pcd(result_dict['out2'][j].cpu().numpy(), os.path.join(save_completion_path, pic))\n",
    "                    plot_single_pcd(gt_cpu[j], os.path.join(save_gt_path, pic))\n",
    "                    plot_single_pcd(inputs_cpu[j].cpu().numpy(), os.path.join(save_partial_path, pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset_test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logging.info('Loss per category:')\n",
    "    category_log = ''\n",
    "    for i in range(16):\n",
    "        category_log += '\\ncategory name: %s ' % (cat_name[i])\n",
    "        for ind, m in enumerate(metrics):\n",
    "            scale_factor = 1 if m == 'f1' else 10000\n",
    "            category_log += '%s: %f ' % (m, test_loss_cat[i, 0] / cat_num[i] * scale_factor)\n",
    "    logging.info(category_log)\n",
    "\n",
    "    logging.info('Overview results:')\n",
    "    overview_log = ''\n",
    "    for metric, meter in test_loss_meters.items():\n",
    "        overview_log += '%s: %f ' % (metric, meter.avg)\n",
    "    logging.info(overview_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dcompletion",
   "language": "python",
   "name": "3dcompletion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
